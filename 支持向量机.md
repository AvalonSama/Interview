# 支持向量机

</br>

#### 什么是支持向量机

- 支持向量机（Support Vector Machines, SVM）是一种**二分类模型**。它的基本模型是定义在特征空间上的**间隔最大的线性分类器**，间隔最大使它有别于感知机；支持向量机还包括核技巧，这使其成为实质上的**非线性分类器**。
- SVM的学习策略就是间隔最大化，可形式化为一个**求解凸二次规划的问题**，也等价于正则化的合页损失函数的最小化问题。
- SVM的最优化算法是求解凸二次规划的最优化算法。
- 对于训练集$T=\{(x_1,y_1),\ldots,(x_N,y_N)\}$，标签$y_i\in\{+1,-1\}$，寻找分类超平面$w^Tx+b=0$。

</br>

#### 什么是支持向量

训练数据集中**与分离超平面距离最近的样本点**的实例称为支持向量

</br>

#### 分类

- **线性可分支持向量机**（硬间隔支持向量机）</br>
  当训练数据线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机。
- **线性支持向量机**（软间隔支持向量机）</br>
  当训练数据接近线性可分时，通过软间隔最大化，学习一个线性分类器，即线性支持向量机。
- **非线性支持向量机**</br>
  当训练数据线性不可分时，通过使用核技巧及软间隔最大化，学习非线性支持向量机。

</br>

#### 函数间隔和几何间隔

- 一个点距离分离超平面的远近可以表示分类预测的**确信程度**。
- 在分类超平面确定的情况下，$|wx+b|$能够相对地表示点$x$距离超平面的远近。而$w^Tx+b$与标签$y$的符号是否一致能够表示分类是否正确。因此**函数间隔表示了分类的正确性和确信度**
  $$
  {\hat{\gamma}}_i=y_i(w^Tx_i+b).
  $$
  而超平面$(w,b)$关于某一训练集$T$的函数间隔指的是所有样本点中函数间隔的最小值
  $$
  \hat{\gamma}=\min{{\hat{\gamma}}_i}.
  $$
- 如果对超平面的法向量$w$增加约束，**使得间隔不随超平面的缩放而变化，引入几何间隔**
  $$
  \gamma_i=\dfrac{y_i}{||w||}(w^Tx_i+b)=\dfrac{\gamma_i}{||w||}.
  $$


</br>

> [!NOTE|label:参考资料]
> [支持向量机通俗导论（理解SVM的三层境界）](https://blog.csdn.net/v_JULY_v/article/details/7624837#commentBox)
>